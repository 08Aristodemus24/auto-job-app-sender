I read your comment also sir sa post ko po with regards to showing more numbers. I just didn't have an idea whether nakasave ng x amount of money yung for example the automation scripts I wrote for the internship I had, so ano po pwede lagay nalang as alternative in cases like these?

* If iko-compare mo yung manual process sa automated process ilan ang mase-save mong time or ilang % mas efficient yung process because of that
* if wala ka naman mapagko-compare-an estimate mo if ilang hours ang ni-run ng automation mo. For example, nagra-run ng 10 mins a day yung automation so, multiply mo yung ng ilang days and months sya nag-run
old: Cleaned, preprocessed, and ingested data for RAG AI agents.
new: cleaned, preprocessed and ingested data approximating 
trust me bros 116
avegotchi 20910
askthesandwich 180
eliza 84
oracle 163
rain 295
sisyphus 9722 
roron 450
sport bettor 469790
500990 total rows produced from cleaning and preprocessing for 9 RAG AI agents
55665.556 rows ingested by retrieval augment generated 


then yun pwede mo ilagay ang x number of hours automated
pero kung mapag-ko-compare-an ka ng numbers na manual vs automated, mas maganda
regarding naman sa money saved
madali na lang yun if may hours ka na ng automated hours
bale ang gagawi mo is e-estimate ka ulit ng cost
for example, ang isang entry level na employee, kaya nya yung manual na ginagawa ng automation
so, say P25,000 per month ang sahod nun

so, P156 per hour ang cost nun.
then multiply mo sa number of hours na gagawin sya nang manual
yun magigung estimated savings mo
then convert mo sya into annual savings


# 
* Move the experience on top if you don't have Professional summar
* Add quantifiable figures to translate them into outcomes of the experience.
* What was the outcome of this project? Was it a success? And how did it create an impact? (Ask chat gpt how it can make an impact)
instead of:
•	Trained a hybrid deep learning model (LSTM-SVM) to denoise (remove artifacts from) electrodermal activity signals and detect points of stress in the signals of an individual. Link to project: https://aristodemus8-eda-denoiser-stress-detector.hf.space/ 
•	Developed a web app to using React and Flask to integrate the trained LSTM-SVM.
•	Evaluated LSTM-SVM using multiple metrics such as ROC-AUC & Accuracy achieving 90% and 78% respectively

we can use the ff:

1. 
"Developed a novel hybrid deep learning model (LSTM-SVM) to automatically denoise electrodermal activity (EDA) signals and accurately detect stress points, improving signal clarity and enabling reliable stress assessment."
"Pioneered a hybrid deep learning approach (LSTM-SVM) for bio-signal denoising and stress detection, addressing critical challenges in physiological data analysis and setting a new benchmark for accuracy."
"Enhanced the accuracy of stress detection by developing a novel hybrid LSTM-SVM deep learning model that effectively denoises electrodermal activity signals."

revised:
Enhanced the accuracy and reliability of bio-signal denoising and stress detection by developing a novel hybrid LSTM-SVM deep learning model, addressing critical challenges in bio-signal data analysis. Link to research: https://aristodemus8-eda-denoiser-stress-detector.hf.space/ 

2. 
"Engineered a user-friendly web application (React/Flask) to integrate the validated LSTM-SVM model, making advanced stress detection accessible for practical application and future research."
"Designed and deployed a full-stack web application (React/Flask) that showcased the practical utility of the stress detection model, demonstrating its potential for real-world health monitoring applications."
"Increased accessibility and practical application of advanced stress detection through the development and integration of a user-friendly React/Flask web application."

revised:
Engineered and deployed a full-stack web application demonstrating the utility and potential of the validated LSTM-SVM model in real world health monitoring applications

3. 
"Validated model performance with 90% ROC-AUC and 78% accuracy in stress point detection, **establishing a robust foundation for future bio-signal research and potential diagnostic tools.**"
"Achieved 90% ROC-AUC and 78% accuracy in model evaluation, **providing compelling evidence for the efficacy of the methodology and contributing significant findings to the field of bio-signal processing.**"
"Validated model robustness by achieving 90% ROC-AUC and 78% accuracy, providing a reliable solution for automated stress assessment from physiological data."

revised:
"Validated model performance with 90% ROC-AUC and 78% accuracy in biosignal denoising and stress point detection, providing a robust foundation and methodology for future bio-signal research and potential diagnostic tools."

4. 
"Designed and deployed a full-stack portfolio website (Svelte & Flask) showcasing diverse data science projects, **effectively demonstrating comprehensive skill mastery across data analysis, machine learning, and web development.**"
Built and launched a dynamic portfolio website (Svelte & Flask) to **centralize and present 10+ data science projects**, significantly enhancing accessibility for recruiters to evaluate technical capabilities and project execution." (You can adjust "10+" to the actual number of projects if it's high enough to be impressive, or remove it if it's low.)
"Developed and maintained a Svelte/Flask portfolio website to effectively present data science projects, providing a clear and accessible demonstration of practical application of analytical skills."

Designed and deployed a full-stack portfolio website to centralize and present 10+ data science projects for recruiters to evaluate, demonstrating technical skills and project execution across data analytics & machine learning.


5. 
Engineered a robust data pipeline utilizing Spark for ingestion and transformation of 20 years of US chronic disease indicator and population data (over X million rows), reducing data preparation time by Y% and enabling efficient aggregation for analysis.
Developed dynamic analytical models to identify correlations between alcohol use indicators and chronic disease mortality across 50+ US states and diverse demographics, providing data-driven insights for public health understanding.
Option 2: Focus on Insights & Impact (if you found specific correlations)

Processed and transformed 20 years of comprehensive US public health data (from 2001-2021) using Spark, consolidating disparate datasets to quantify chronic disease cases and population figures at a granular state level.
Conducted in-depth analysis of key chronic disease indicators linked to alcohol consumption, identifying significant positive correlations between binge drinking frequency/intensity and chronic liver disease mortality rates across various demographics and states. This insight highlights critical areas for public health intervention.
Option 


Leveraged Spark to extract and transform 20 years of chronic disease and population data across US states, optimizing data aggregation efficiency by Y% for subsequent analysis.
Uncovered critical insights from alcohol-related chronic disease indicators, pinpointing statistically significant correlations between specific drinking patterns and chronic liver disease mortality rates across diverse demographics and US states, informing potential public health strategies.

* What was the impact of the project-alexander?
* What was the analysis of the chronic-disease-indicators about?
